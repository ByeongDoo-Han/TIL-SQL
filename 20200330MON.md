:v:
---
# 데이터 분석
## 데이터 분석 분류
### :heavy_check_mark: 머신러닝(기계학습)
- 사용자가 직접 데이터의 패턴, rule을 찾지 않고 데이터의 학습을 통해 자동으로 패턴을 찾을 수 있도록 하는 분석기법

#### 지도학습(supervised learning)
`타겟값, 종속변수, Y 존재`

- Y에 영향을 미치는 설명변수의 최적의 조합을 찾는 과정
(변수의 선택 및 제거, 변수의 결합 및 변형)

##### 1. 회귀기반 모델
- Y가 연속형일 경우
`부동산 가격 예측, 수요예측...`
##### 2. 분류기반 모델
- Y가 범주형일 경우
`생존여부 예측, 이탈여부 예측...`




#### 비지도학습(unsupervised learning)
`타겟값, 종속변수, Y 존재` :x:
        
- x들이 갖는 각 관측치의 유사성을 기반으로 데이터를 세분화

### :heavy_check_mark: 딥러닝
- 머신러닝의 일부, 딥러닝에 대한 연구가 강화되면서 기존 머신러닝에서 분리하여 설명하는 추세
- 주로 인공신경망 모델을 사용한 분석기법을 의미
- 머신러닝에 비해 비정형화된 데이터 처리에 용이함
`비정형 데이터란? - 이미지, 음성, 영상`


# 시각화
- 시각화할 데이터 로드시에 `stringsAsFactors = F`로 옵션을 주게 되면 시각화 컬러를 지정할 때 컬럼을 바로 줄 수 없다. 컬러 옵션에서 컬럼을 받을 때는 Factor 타입으로 받기 때문 :star:

---
# 데이터 분석의 순서
1. **데이터 수집**
2. **변수연구 ( 어떤 변수로 설명할 것인가 )**
3. **전처리**
4. **이상치, 결측치 처리**

# [ 분류분석 - 범주형 ] 
X들이 가지는 패턴에 따라 Y의 종류를 에측하기 위한 분석
- 분류분석 과정
    - 데이터 수집(Y에 영향을 미칠만한 모든 데이터)
    - 변수연구(feature selection/변수결합/변수변형)
    - 이상치 및 결측치 처리
    - 모델 선택
    - data sampling(train set/validation set/test set)
    - 모델 학습(train set)
    - 모델 평가(test set)
    `실제 정답과 예측값과의 일치율로 평가`
    - 모델 튜닝(validation set)
    - 결과 해석


- 분석기법 종류
    1. kNN
        - 거리기반
    2. NB
        - 통계기반, 확률기반
    3. DT
        - 트리기반, 단일 의사결정
    4. RF
        - 트리기반
    5. SVM
        - 회귀 기반 모델
        - 난이도 높다
        - 해석, 패턴확인 어렵다
            - 블랙박스 모델


## :heavy_check_mark: Decision Tree (의사결정나무)
- 분류분석을 수행하는 트리기반 모델의 가장 초기 모델
- 한번의 패턴확인으로 Y를 예측
- 패턴이 Tree 구조를 띔
- 비통계적 모델로 모델 적용 및 해석이 매우 쉽다
- 단일의사결정이므로 예측력이 불안하거나 overfit될 수 있음
- 가장 예측력이 우수한 중요질문을 상위 노드 (Root) 에 배치한다.

    **overfit이란?**
train data에 대한 과도하게 세세한 학습으로 인해 새로운 데이터(**new data** or **test data**)에 대한 예측력이 떨어지는 현상


### 모델 시각화
`rpart`, `rpart.plot`
```r
install.packages('rpart')
library(rpart)

m_dt <- rpart(Species ~., data = iris)
m_dt

dev.new()
plot(m_dt, compress= T)
text(m_dt, cex=1.5)
```
```r
install.packages('rpart.plot')
library(rpart.plot)
prp(m_dt, type=4, extra = 2, digits = 3)
```



`console`에서 해석방법
- 1). 동일 비율일 때는 가장 앞에 있는 대상(0.3333)의 이름
- 2). node 마지막에 * 가 찍혀있는것은 분류가 끝났다는 의미
- 3). node에는 질문을 주고 질문에 대한 정분류개수와 오분류개수를 표시함

```
> m_dt
n= 150 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

1) root 150 100 setosa (0.33333333 0.33333333 0.33333333)  
  2) Petal.Length< 2.45 50   0 setosa (1.00000000 0.00000000 0.00000000) *
  3) Petal.Length>=2.45 100  50 versicolor (0.00000000 0.50000000 0.50000000)  
    6) Petal.Width< 1.75 54   5 versicolor (0.00000000 0.90740741 0.09259259) *
    7) Petal.Width>=1.75 46   1 virginica (0.00000000 0.02173913 0.97826087) *
```

### 평가점수를 일반화
평가점수 일반화를 위해 데이터셋을 train, test 7:3으로 나눠준다. 경험적으로 예측 성공률이 올라가기 때문이다.

1. sampling
```r
v_rn <- sample(1:nrow(iris), size = nrow(iris) * 0.7)
iris_train <- iris[v_rn, ]
iris_test <- iris[-v_rn, ]
```

2. modeling
```r
m_dt <- rpart(data = iris_train, formula = Species ~ .)
```

3. 모델 시각화
4. 모델 평가
```r
iris_test$Species
predict(m_dt, newdata = iris_test, type='class')
```

5. score
:warning: test set을 predict에도 이용하는 이유
>predict는 예측하고 싶은 y값을 모른다는 가정하에 예측을 시도하고 test set과 비교하기 위함
```r
v_y <- iris_test$Species
v_predict <- predict(m_dt, newdata = iris_test, type='class')

v_score <- sum(v_y == v_predict) / nrow(iris_test) * 100
```

6. 모델튜닝
```r
m_dt$control 
# $minbucket 값의 의미는 추가 분류를 시도할 최소한의 원소갯수의 기준을 표시
```

- 매개변수 종류
    - minbucket
    - minsplit
    `minbucket = round(minsplit/3)`
    - cp
    - maxdepth

- 매개변수 조정
```r
m_dt2 <- rpart(data = iris_train,
               formula = Species ~ . ,
               control = rpart.control(minbucket=2))
m_dt2
```
- 최적의 매개변수 값 확인
minbucket이 1~10 변화될 때의 예측력 변화를 확인한다.
overfit 여부까지 확인
- 1부터 10까지의 train dataset 점수와 test dataset의 점수를 비교하고 변화 정도 확인

```r
v_tr_score <- c()
v_te_score <- c()
for ( i in 1:10) {
    m_dt <- rpart(data = iris_train,
                  formula = Species ~ . ,
                  control = rpart.control(minbucket=i))
    
    # train data score
    tr_pre <- predict(m_dt, newdata=iris_train, type='class' )
    tr_score <- sum(iris_train$Species == tr_pre)/nrow(iris_train) * 100
    
    # test data score
    te_pre <- predict(m_dt, newdata = iris_test, type = 'class')
    te_score <- sum(iris_test$Species == te_pre)/nrow(iris_test) * 100
    
    # 벡터화
    v_tr_score <- c(v_tr_score, tr_score)
    v_te_score <- c(v_te_score, te_score)
}

v_tr_score
v_te_score
```
- 서로 10% 가까이 차이가 난다면 overfit이 발생했다고 볼 수 있다.


### Cancer data
```r
cancer <- read.csv('cancer.csv')

dev.new()
plot(cancer[,3:11], col = cancer$diagnosis)
```
- 데이터프레임에 plot을 씌우면 교차 산점도를 표현하는데 이때 컬럼간의 상호연관성이 높은 컬럼을 식별할 수 있고, 이를 통해 각 설명변수의 중요도의 의미를 파악할 수 있다.


---
:fire:
---