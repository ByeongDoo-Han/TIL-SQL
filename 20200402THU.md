:v:
---
# k-means 수행 시 적절한 군집의 수 구하기
- 군집의 수는 이미 정해져 있거나, 군집분석의 결과를 보고 정하는데 적절한 군집의 수를 참고할 수 있는 지표 제공

```r
install.packages('NbClust')
library(NbClust)

iris_sc1 <- scale(iris[,-5])
iris_sc2 <- scale(iris[,c(3,4)])

dev.new()
nc1 <- NbClust(data = iris_sc2 ,  # 데이터(거리행렬 아님)
               distance = 'euclidean',       # 거리계산방법
               min.nc = 2,                   # 최소 군집수
               max.nc = 10,                  # 최대 군집수
               method = 'average')           # 군집과의 거리 계산 방법
```

```
# ******************************************************************* 
# * Among all indices:                                                
# * 8 proposed 2 as the best number of clusters 
# * 9 proposed 3 as the best number of clusters 
# * 1 proposed 4 as the best number of clusters 
# * 1 proposed 7 as the best number of clusters 
# * 2 proposed 8 as the best number of clusters 
# * 1 proposed 9 as the best number of clusters 
# * 1 proposed 10 as the best number of clusters 
# 
# ***** Conclusion *****                            
# 
# * According to the majority rule, the best number of clusters is  3 
```
- 많은 지표가 선택되는것이 좋다.
- 9개의 지표를 고려할 때 클러스터를 3개로 설정하는 것이 좋다.


---
# 군집분석

- Y가 없는 비지도 학습
- 모집단을 세분류한 후 집단의 특성을 파악하는 마이닝 작업
- `Clustering`
    - 데이터 축소 테크닉
    - 분류된 집단의 특성을 파악한 이후 지도학습으로도 추가연구 가능

## :heavy_check_mark: 계층적 군집분석 `kNN`
- 밑부터 순차적으로 군집화
- 거리가 가장 짧은 데이터 포인트들로부터 인근의 데이터포인트를 포함시키는 방향으로 군집형성
- 특정 군집에 한번 포함되면 군집 수정 불가능
- 군집을 형성하는 과정에 따라 여러가지 방식 제공


데이터포인트와 군집과의 거리 측정 방식에 따라
1. 최단거리법 (single, min)
2. 최장거리법 (complete, max)
3. 평균거리법 (average)
4. 중앙거리법 (median)

### 군집형성과정
1. 각 데이터포인트들끼리의 거리 중 가장 가까운 데이터 군집(cluster) 형성
2. 형성된 클러스터와 나머지 데이터포인트들끼리의 거리계산,
이 때 거리 측정방식에 차이를 둔다.
3. 위 거리 중 가장 짧은 데이터포인트끼리 새로운 군집을 형성하거나 기존클러스터(c1)에 새로운 데이터포인트를 추가한다.
4. c1과 데이터포인트의 거리계산
5. 군집 시각화

```r
v1 <- c(1,2,6,10,18)
d1 <- dist(v1)
m_clust <- hclust(d1, 
                  method = 'complete' or
                           'single' or
                           'average' or
                           'median')
plot(m_clust,
     hang = -1,
     cex = 0.8,
     main = 'title')

rect.hclust(tree = m_clust,
               k = 2))
```

### iris 표준화 후 군집형성
scale => 데이터프레임 표준화
dist => 각 포인트의 거리
hclust => 가장 짧은 거리부터 군집 만들고 `average`방법으로 군집 추가
cutree => k(군집의 개수)를 3개로 설정하고 군집 늘려감


```r
m1 <- hclust(dist(scale(iris[,c(3,4)])), 'average') # petal칼럼만 반영
c1 <- cutree(m1, k=3)

y_result <- iris$Species
levels(y_result) <- c(1,2,3) # 각 factor가 설정된 순서에 따라서 숫자 순서 바꿔줌. 

sum(y_clust == c1) / nrow(iris) * 100 # 점수확인

dev.new()
plot(m1,
     hang = -1,
     cex = 0.8,
     main = 'title')
rect.hclust(m1, 3)
```

## :heavy_check_mark: 비계층적 군집분석 `k-means`
- 이미 한 군집에 포함되었더라도 다른 군집으로 이동 가능
- 계속 군집의 중심을 이동, 거리를 재계산하여 
군집의 재형성을 수차례 반복, 
- 더이상 군집의 중심에
변화가 없을때 stop
- 평가 metric 존재 ( 군집간 분산, 군집내 분산)

### 비계층적 군집분석의 군집형성과정
1) 초기값 생성(랜덤)
2) 랜덤하게 생성된 관측치로부터 가장 가까운 관측치와 군집형성
3) 이후 거리 계산, 새로운 클러스터 형성은 계층적 방법과 동일
4) 이동된 군집의 중심기준 기존 관측치와의 거리를 모두 재계산
   (군집내 포함되어 있는 관측치들도 모두 개별관측치로 보고 계산)
5) 만약 특정 관측치와의 거리가 기존 군집보다 새로 이동된 군집과 
    더 가깝다면 관측치의 군집이 이동
6) 더이상 모든 군집의 중심의 변화가 없을때까지 무한 반복

### 군집평가 시 필요한 분산
- `총분산(total_ss)` 
  within_ss + between_ss
- `군집내분산(within_ss)` 
특정 군집 내에서의 분산
- `군집간분산(between_ss)` 
각 군집간의 분산

### iris 데이터를 사용한 <mark>k_means</mark> 군집분석

#### 1. 모델생성
```r
m_kmean <- kmeans(iris[,-5],3)
```

#### 2. 모델 평가

- 분산으로 해석(평가점수)
> m_kmeans$betweenss / m_kmeans$totss * 100 ==> 높을수록 효과적인 클러스터링,
총분산은 고정값이지만 betweenss는 가변, 따라서 클러스터링이 잘될수록 
betweenss가 높아진다

> k값을 올릴수록 withinss가 떨어지기때문에 자동으로 betweenss는 올라간다.
하지만 평가점수는 계속 올라가지만 의미 없는 증가일 뿐이다.
따라서 적절한 k의 수를 찾아야 하고 
plot을 그려서 elbow point를 찾아서 k 값을 설정해야한다.

- 일치율로 해석
> iris의 정답데이터를 알기때문에  비교목적으로 수행
실제 군집분석에서는 하지 않는 과정

```r
y_result2 <- iris$Species
levels(y_result2) <- c(3,1,2)
y_result2

sum(y_result2 == m_kmean$cluster) / nrow(iris) * 100
```
- 적절한 k수 찾기
```r
vscore <- c()

for (i in 1:10) {
  m_kmean <- kmeans(iris[,-5], i)
  vscore <- c(vscore, m_kmean$betweenss / m_kmean$totss * 100)
}

dev.new()
plot(1:10, vscore, type='o', col='blue',
     xlab = '군집수(k)', ylab = 'betweenss / totss',
     main='군집수의 변화에 따른 betweenss / totss')
```

---
:fire:
---