:v:
---
# :heavy_check_mark: 표준화
- 각 측정치의 스케일이 다르면 컬럼중요도가 변하기 때문에 스케일을 맞추는 과정이 필요한데 이를 표준화라고 한다.
```
   x1 x2
p1 5  100
p2 6  200
p3 10 150
```

```
1) 일반거리
d12 <- sqrt(1+10000)
d13 <- sqrt(25  + 2500)
d12
d13

2) 표준화된 거리
(5-6)/0.01
```

>편차 = (x-평균)
분산 = sum(편차^2)/개수
표준편차 = sqrt(분산)
표준화된 x == 편차 / 표준편차

# :heavy_check_mark: 지도학습과 비지도학습
1. 지도학습

    1) 회귀분석
    2) 분류분석
    -트리기반 : DT, RF, GB, XGB
    -거리기반 : knn

2. 비지도학습
    
    1) 군집분석 : kclust, k-means
    2) 연관성분석

## [군집분석]
- 대표적인 비지도 학습모델
- 데이터들의 유사성 기반으로 세분화,데이터 축소 테크닉
- 거리모델의 특징 모두 가짐
- 이상치 민감, 스케일 조정 필요
- 선택되어진 변수의 조합이 중요한 모델 
---
# y가 연속형인 경우의 분석 방법
## :heavy_check_mark: 전통 회귀분석
- 여러가지 통계적 가정 필요
- 가정이 만족되지 않으면 예측력이 떨어짐
- 인과관계 파악 용이 (특정 설명변수의 영향력)

## :heavy_check_mark: 분류분석 모델의 회귀분석
- 비통계적 모델로 통계적 가정 및 해석 필요 없음
- 비교적 간단한 모델
- 인과관계 파악 어려움

### 트리기반모델
#### `DT > RF > GB > XGB`
- outlier에 민감하지 않음

### 거리기반모델

#### `knn`
```r
install.packages('class')
library(class)

knn(train_x, #훈련 x set
    test_x,  #예측 x set
    train_y, # 훈련 y set
    k = 3,   # 이웃의 수
    prob=T)  # 확률 출력 여부
```

- outlier에 매우 민감
- 설명변수의 스케일 조정이 필요함
- 각 관측치의 거리를 계산, 가장 가까운 데이터의 행동을 그대로 추천
- 추천시스템, 이미지 인식 시스템의 기본이 되는 알고리즘 
- 거리는 스케일 조정이 반드시 필요
- 이상치에 매우 민감한 모델
- k개의 가장 가까운(거리기반) 이웃을 찾아 이웃이 갖는 범주로 예측을 수행하는 모델
- 적절한 k는 튜닝될 필요 있음
- y의 종류가 2개일경우, k가 짝수일 경우 
동률발생으로 인해 예측력이 떨어질 수 있음
k=4, 2명 A , 2명 B => 'A'

```
  소득 직업      지출 A상품구매여부
1 400  회사원(1) 200  X
2 410  회사원    220  X
3 500  자영업(2) 400  O

4 420 회사원 180 ? (X일 가능성이 높아보임)
```

```r
d14 <- sqrt((400-420)^2 + (1-1)^2 + (200-180)^2) #28.28
d24 <- sqrt((410-420)^2 + (1-1)^2 + (220-180)^2) #41.23
d34 <- sqrt((500-420)^2 + (2-1)^2 + (400-180)^2) #234.23
```

- knn에선 factor형 변수(회사원, 자영업같은 이진데이터)가 많을수록 예측력이 떨어진다.

- 결론 : 4번 관측치와 가장 가까운 이웃 1명을 고려시, 1번 관측치의
구매여부를 따를것으로 예상


**1. sampling**
```r
v_rn <- sample(1:nrow(iris), size = 0.7*nrow(iris))
iris_tr_x <- iris[v_rn, -5]
iris_tr_y <- iris[v_rn, 5]
iris_te_x <- iris[-v_rn, -5]
iris_te_y <- iris[-v_rn, 5]
```

**2. 모델학습**

```r
m_knn <- knn(iris_tr_x, iris_te_x, iris_tr_y, k=3, prob=T)
m_knn
```

**3. 모델평가**

```r
sum(m_knn == iris_te_y)/nrow(iris_te_x) * 100
```
**4. 새로운 데이터에 대한 예측**

```r
newdata <- iris_te_x[7,]
knn(iris_tr_x, newdata, iris_tr_y, k=3, prob=T)

predict(m_knn, newdata=newdata, type='class')
```

**5. 매개변수 튜닝**
k 변화에 따른 에측률 변화 추이

#### **[cancer - knn연습문제]**

```r
cancer <- read.csv('cancer.csv')

# 1. sampling
rn <- sample(1:nrow(cancer), size = 0.7*nrow(cancer))

train_x <- cancer[rn, -c(1,2)]
train_y <- cancer[rn, 2]
test_x  <- cancer[-rn, -c(1,2)]
test_y  <- cancer[-rn, 2]

sample_n <- sample(1:nrow(test_x), size = 1)
newdata_x <- test_x[sample_n, ]
newdata_y <- test_y[sample_n]

test_x  <- test_x[-sample_n, ]
test_y  <- test_y[-sample_n]

# 2. model 생성
m_knn <- knn(train_x, test_x, train_y, k=3)

# 3. 평가
sum(m_knn==test_y) / nrow(test_x) * 100

# 4. k 튜닝
sc_tr <- c() ; sc_te <- c()
for (i in 1:10) {
  m_knn1 <- knn(train_x, train_x, train_y, k=i)
  m_knn2 <- knn(train_x, test_x, train_y, k=i)
  
  sc_tr <- c(sc_tr, sum(m_knn1==train_y)/nrow(train_x) * 100)
  sc_te <- c(sc_te, sum(m_knn2==test_y)/ nrow(test_x) * 100)
}

dev.new()
plot(1:10, sc_tr, type = 'o', col = 'blue', ylim=c(80,100),
     xlab='k수', ylab='score', main='k에 따른 예측률 변화')
lines(1:10, sc_te, type = 'o', col = 'red')
legend(8,100, c('train','test'),col = c('blue','red'), lty=1)
```




---
:fire:
---